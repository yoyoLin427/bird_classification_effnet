# -*- coding: utf-8 -*-
"""bird_v11_SGD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTn-Kbm_WVl8kJwXgI2uG53HUHyYvAog

https://colab.research.google.com/github/Tony607/efficientnet_keras_transfer_learning/blob/master/Keras_efficientnet_transfer_learning.ipynb#scrollTo=SmzQmZdKDfSF
"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
import os
import glob
import shutil
import sys
import numpy as np
from skimage.io import imread
import matplotlib.pyplot as plt
from IPython.display import Image
# %matplotlib inline

batch_size = 32 #改

width = 448
height = 448
epochs = 20
dropout_rate = 0.2 #改
input_shape = (height, width, 3)

# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3
# Higher the number, the more complex the model is.
from tensorflow.keras.applications import EfficientNetB0 as Net

# loading pretrained conv base model
conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)

import numpy as np 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
from google.colab import drive
drive.mount('/content/drive')

import shutil
#os.mkdir('/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/train')

class_path = '/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/classes.txt'
with open(class_path) as f:
  classes = [x.strip() for x in f.readlines()]  # all the testing images

#for i in classes:
#  os.mkdir('/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/train/'+i[0:3])

BASE_DIR = '/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/new_split'
print('BASE_DIR contains ', os.listdir(BASE_DIR))
TRAIN_DIR = os.path.join(BASE_DIR, 'train')
VALIDATION_DIR = os.path.join(BASE_DIR, 'val')
print(len(os.listdir(TRAIN_DIR)))
print(len(os.listdir(VALIDATION_DIR)))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

# Note that the validation data should not be augmented!
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
        # This is the target directory
        TRAIN_DIR,
        # All images will be resized to target height and width.
        target_size=(height, width),
        batch_size=batch_size,
        # Since we use categorical_crossentropy loss, we need categorical labels
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        VALIDATION_DIR,
        target_size=(height, width),
        batch_size=batch_size,
        class_mode='categorical')

model = models.Sequential()
model.add(conv_base)
model.add(layers.GlobalMaxPooling2D(name="gap"))
# model.add(layers.Flatten(name="flatten"))
if dropout_rate > 0:
    model.add(layers.Dropout(dropout_rate, name="dropout_out"))
# model.add(layers.Dense(256, activation='relu', name="fc1"))
model.add(layers.Dense(200, activation='softmax', name="fc_out"))

model.summary()

print('This is the number of trainable layers '
      'before freezing the conv base:', len(model.trainable_weights))

conv_base.trainable = False

print('This is the number of trainable layers '
      'after freezing the conv base:', len(model.trainable_weights))

import tensorflow as tf
model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc'])
#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)
#model.compile(loss='categorical_crossentropy',
              #optimizer=optimizer,
              #metrics=['acc'])
model.summary()

history = model.fit(
      train_generator,
      epochs=30,
      validation_data=validation_generator,
      verbose=1)

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_x = range(len(acc))

plt.plot(epochs_x, acc, 'bo', label='Training acc')
plt.plot(epochs_x, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs_x, loss, 'bo', label='Training loss')
plt.plot(epochs_x, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

model.summary()

def unfreeze_model(model):
    for layer in model.layers: 
      layer.trainable = True
    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc'])


unfreeze_model(model)
model.summary()

"""改變batch size 從32到8"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

# Note that the validation data should not be augmented!
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
        # This is the target directory
        TRAIN_DIR,
        # All images will be resized to target height and width.
        target_size=(height, width),
        batch_size=8,
        # Since we use categorical_crossentropy loss, we need categorical labels
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        VALIDATION_DIR,
        target_size=(height, width),
        batch_size=8,
        class_mode='categorical')

history = model.fit(
      train_generator,
      epochs=15,
      validation_data=validation_generator,
      verbose=1)

from google.colab import files
model.save('my_model') 
files.download('my_model')

model.save('model_v11_SGD.h5') 
files.download('model_v11_SGD.h5')

import os
import numpy as np
import numpy as np
from keras.preprocessing.image import img_to_array, load_img


with open('/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/testing_img_order.txt') as f:
     test_images = [x.strip() for x in f.readlines()]  # all the testing images

submission = []
i=0
for img_name in test_images:  # image order is important to your result
  img_path = '/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/testing_images/'+img_name
  img = load_img(img_path, target_size=(448, 448))  # this is a PIL image
  x = img_to_array(img)  # Numpy array with shape (150, 150, 3)
  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)

  result = model.predict(x)
  cn = np.argmax(result,axis=1)
  submission.append([img_name, classes[cn[0]]])
  i +=1
  print(i)
  print([img_name, classes[cn[0]]])

np.savetxt('answer_v13_0.txt', submission, fmt='%s')
files.download('answer_v13_0.txt')