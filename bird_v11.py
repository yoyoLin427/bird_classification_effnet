# -*- coding: utf-8 -*-
"""bird_v11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nwUgQaNHvLMvkumtx55-w-FM2MZ0nOkK

參考:
1.	https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/
2.	https://colab.research.google.com/github/Tony607/efficientnet_keras_transfer_learning/blob/master/Keras_efficientnet_transfer_learning.ipynb#scrollTo=SmzQmZdKDfSF
"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
import os
import glob
import shutil
import sys
import numpy as np
from skimage.io import imread
import matplotlib.pyplot as plt
from IPython.display import Image
# %matplotlib inline

"""## batch size、image size
減少batch size有助於提高validation accuracy

放大image size也會讓模型表現更加
"""

batch_size = 32

width = 448
height = 448
epochs = 20
dropout_rate = 0.2
input_shape = (height, width, 3)

# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3
# Higher the number, the more complex the model is.
from tensorflow.keras.applications import EfficientNetB0 as Net

"""## 使用effecientnet作為pretrain model"""

# loading pretrained conv base model
conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)

import numpy as np 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
from google.colab import drive
drive.mount('/content/drive')

import shutil
#os.mkdir('/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/train')

class_path = '/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/classes.txt'
with open(class_path) as f:
  classes = [x.strip() for x in f.readlines()]  # all the testing images

#for i in classes:
#  os.mkdir('/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/train/'+i[0:3])

BASE_DIR = '/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/new_split'
print('BASE_DIR contains ', os.listdir(BASE_DIR))
TRAIN_DIR = os.path.join(BASE_DIR, 'train')
VALIDATION_DIR = os.path.join(BASE_DIR, 'val')
print(len(os.listdir(TRAIN_DIR)))
print(len(os.listdir(VALIDATION_DIR)))

"""## 資料擴增
因為原本的資料太少了 每個類別都只有15張圖片
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

# Note that the validation data should not be augmented!
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
        # This is the target directory
        TRAIN_DIR,
        # All images will be resized to target height and width.
        target_size=(height, width),
        batch_size=batch_size,
        # Since we use categorical_crossentropy loss, we need categorical labels
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        VALIDATION_DIR,
        target_size=(height, width),
        batch_size=batch_size,
        class_mode='categorical')

"""# 建model

後面增加的layer我覺得越簡單表現會越好
"""

model = models.Sequential()
model.add(conv_base)
model.add(layers.GlobalMaxPooling2D(name="gap"))
# model.add(layers.Flatten(name="flatten"))
if dropout_rate > 0:
    model.add(layers.Dropout(dropout_rate, name="dropout_out"))
# model.add(layers.Dense(256, activation='relu', name="fc1"))
model.add(layers.Dense(200, activation='softmax', name="fc_out"))

model.summary()

"""## 第一批訓練,不訓練pretrain model的layer"""

print('This is the number of trainable layers '
      'before freezing the conv base:', len(model.trainable_weights))

conv_base.trainable = False

print('This is the number of trainable layers '
      'after freezing the conv base:', len(model.trainable_weights))

import tensorflow as tf
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)
model.compile(loss='categorical_crossentropy',
              optimizer=optimizer,
              metrics=['acc'])
model.summary()

history = model.fit(
      train_generator,
      epochs=epochs,
      validation_data=validation_generator,
      verbose=1)

history = model.fit(
      train_generator,
      epochs=epochs,
      validation_data=validation_generator,
      verbose=1)

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_x = range(len(acc))

plt.plot(epochs_x, acc, 'bo', label='Training acc')
plt.plot(epochs_x, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs_x, loss, 'bo', label='Training loss')
plt.plot(epochs_x, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

model.summary()

"""## 第二批訓練,unfreez layer,讓整個模型都參與訓練"""

def unfreeze_model(model):
    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen
    for layer in model.layers[-20:]:
        if not isinstance(layer, layers.BatchNormalization):
            layer.trainable = True

    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
    model.compile(
        optimizer=optimizer, loss="categorical_crossentropy", metrics=["accuracy"]
    )


unfreeze_model(model)
model.summary()

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

# Note that the validation data should not be augmented!
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
        # This is the target directory
        TRAIN_DIR,
        # All images will be resized to target height and width.
        target_size=(height, width),
        batch_size=8,
        # Since we use categorical_crossentropy loss, we need categorical labels
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        VALIDATION_DIR,
        target_size=(height, width),
        batch_size=8,
        class_mode='categorical')

history = model.fit(
      train_generator,
      epochs=epochs,
      validation_data=validation_generator,
      verbose=1)

from google.colab import files
model.save('model_v11.h5') 
files.download('model_v11.h5')

"""# 結果"""

import os
import numpy as np
import numpy as np
from keras.preprocessing.image import img_to_array, load_img


with open('/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/testing_img_order.txt') as f:
     test_images = [x.strip() for x in f.readlines()]  # all the testing images

submission = []
i=0
for img_name in test_images:  # image order is important to your result
  img_path = '/content/drive/MyDrive/碩一上/作業/基於深度學習之視覺辨識/HW1/testing_images/'+img_name
  img = load_img(img_path, target_size=(448, 448))  # this is a PIL image
  x = img_to_array(img)  # Numpy array with shape (150, 150, 3)
  x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)

  result = model.predict(x)
  cn = np.argmax(result,axis=1)
  submission.append([img_name, classes[cn[0]]])
  i +=1
  print(i)
  print([img_name, classes[cn[0]]])

np.savetxt('answer_v11.txt', submission, fmt='%s')
files.download('answer_v11.txt')